# Enhancing Facial Privacy Protection via Weakening Diffusion Purification (CVPR 2025) [[ArXiv](https://arxiv.org/abs/2503.10350)] 

<p align="center">
 <a href="https://parham1998.github.io/" target="_blank">Ali Salar</a>,
 <a href="https://sites.google.com/site/qingliucs/home" target="_blank">Qing Liu</a>,
 <a href="https://media-lab.ccny.cuny.edu/YLTCCNYHomepage/home.html" target="_blank">Yingli Tian</a>,
 <a href="https://gyzhao-nm.github.io/Guoying/" target="_blank">Guoying Zhao</a>,
 <br>
</p>

## Abstract
<p align="justify"> The rapid growth of social media has led to the widespread sharing of individual portrait images, which pose serious privacy risks due to the capabilities of automatic face recognition (AFR) systems for mass surveillance. Hence, protecting facial privacy against unauthorized AFR systems is essential. Inspired by the generation capability of the emerging diffusion models, recent methods employ diffusion models to generate adversarial face images for privacy protection. However, they suffer from the diffusion purification effect, leading to a low protection success rate (PSR). In this paper, we first propose learning unconditional embeddings to increase the learning capacity for adversarial modifications and then use them to guide the modification of the adversarial latent code to weaken the diffusion purification effect. Moreover, we integrate an identity-preserving structure to maintain structural consistency between the original and generated images, allowing human observers to recognize the generated image as having the same identity as the original. Extensive experiments conducted on two public datasets, i.e., CelebA-HQ and LADN, demonstrate the superiority of our approach. The protected faces generated by our method outperform those produced by existing facial privacy protection approaches in terms of transferability and natural appearance. </p>

## Setup
- **Get code**
```shell 
git clone https://github.com/parham1998/Facial-Privacy-Protection.git
```

- **Build environment**
```shell
cd Facial-Privacy-Protection
# use anaconda to build environment 
conda create -n Facial-Privacy-Protection python=3.11
conda activate Facial-Privacy-Protection
# install packages
pip install -r requirements.txt
```

- **Download assets**
  - Download pre-trained face recognition models and datasets from [AMT-GAN](https://github.com/CGCL-codes/AMT-GAN) and place them in the assets folder

- **The final assets folder should be like this:**
```shell
assets
  └- datasets
    └- CelebA-HQ
    └- CelebA-HQ-500_pairs
    └- LADN
  └- face_recognition_models
    └- facenet.pth
    └- facenet.py
    └- ...
  └- obfs_target_images
  └- target_images
  └- test_images
```

- **Aligning the images in the dataset folder before starting the protection:**
```shell
python align.py
```

- **For impersonation:**
```shell
source_dir=source images folder path for impersonation
is_obfuscation=False
MTCNN_cropping=True
target_choice=Choice of target identity, as in AMT-GAN: 1, 2, 3, 4
```

- **For obfuscation:**
```shell
source_dir=source images folder path for obfuscation
test_dir=test images folder path for obfuscation
is_obfuscation=True
MTCNN_cropping=False
target_choice=5
```

5. Run the code:
```shell
python main.py
```

## Citation 
```bibtex
@InProceedings{}
```

## Acknowledgments
Our code structure is based on [Prompt-to-Prompt](https://github.com/google/prompt-to-prompt)
